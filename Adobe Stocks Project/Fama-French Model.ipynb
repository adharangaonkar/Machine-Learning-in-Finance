{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "amateur-proportion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader.data as reader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import statsmodels.api as sm\n",
    "import datetime\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "average-puzzle",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = (datetime.datetime(2018, 1, 1))\n",
    "end = (datetime.datetime(2020, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "outdoor-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = ['ADBE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fluid-consumption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "                  open        high         low       close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2018-01-02  175.850006  177.800003  175.259995  177.699997  177.699997   \n",
      "2018-01-03  178.000000  181.889999  177.699997  181.039993  181.039993   \n",
      "2018-01-04  181.929993  184.059998  181.639999  183.220001  183.220001   \n",
      "2018-01-05  185.000000  185.899994  183.539993  185.339996  185.339996   \n",
      "2018-01-08  184.949997  185.600006  183.830002  185.039993  185.039993   \n",
      "\n",
      "             volume  \n",
      "Date                 \n",
      "2018-01-02  2432800  \n",
      "2018-01-03  2561200  \n",
      "2018-01-04  2211400  \n",
      "2018-01-05  2376500  \n",
      "2018-01-08  2088000  \n"
     ]
    }
   ],
   "source": [
    "start = (datetime.datetime(2018, 1, 1))\n",
    "end = (datetime.datetime(2020, 1, 1))\n",
    "\n",
    "data = yf.download(symbol, start=start, end=end)\n",
    "data.rename(columns={\"Close\": 'close', \"High\": 'high', \"Low\": 'low', 'Volume': 'volume', 'Open': 'open'}, inplace=True)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "august-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"Adj Close\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "computational-alexandria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>177.699997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>181.039993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>183.220001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>185.339996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>185.039993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>329.640015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>331.200012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>330.790009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>328.339996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>329.809998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Adj Close\n",
       "Date                  \n",
       "2018-01-02  177.699997\n",
       "2018-01-03  181.039993\n",
       "2018-01-04  183.220001\n",
       "2018-01-05  185.339996\n",
       "2018-01-08  185.039993\n",
       "...                ...\n",
       "2019-12-24  329.640015\n",
       "2019-12-26  331.200012\n",
       "2019-12-27  330.790009\n",
       "2019-12-30  328.339996\n",
       "2019-12-31  329.809998\n",
       "\n",
       "[503 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "thirty-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.diff(np.log(data['Adj Close']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "municipal-breast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "incorrect-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(Y, columns = ['Adj Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "complex-vitamin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.001620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.002095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.004721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>-0.001239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>-0.007434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.004467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>502 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Adj Close\n",
       "0     0.018621\n",
       "1     0.011970\n",
       "2     0.011504\n",
       "3    -0.001620\n",
       "4     0.008931\n",
       "..         ...\n",
       "497   0.002095\n",
       "498   0.004721\n",
       "499  -0.001239\n",
       "500  -0.007434\n",
       "501   0.004467\n",
       "\n",
       "[502 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "understanding-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = pd.read_csv(\"fama-french.csv\", skiprows=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "crucial-render",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Mkt-RF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>RMW</th>\n",
       "      <th>CMA</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19630701</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19630702</td>\n",
       "      <td>0.79</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19630703</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19630705</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19630708</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14509</th>\n",
       "      <td>20210222</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>0.68</td>\n",
       "      <td>3.14</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14510</th>\n",
       "      <td>20210223</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.08</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14511</th>\n",
       "      <td>20210224</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.34</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14512</th>\n",
       "      <td>20210225</td>\n",
       "      <td>-2.73</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14513</th>\n",
       "      <td>20210226</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14514 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Mkt-RF   SMB   HML   RMW   CMA     RF\n",
       "0        19630701   -0.67  0.00 -0.34 -0.01  0.15  0.012\n",
       "1        19630702    0.79 -0.27  0.27 -0.07 -0.19  0.012\n",
       "2        19630703    0.63 -0.17 -0.10  0.17 -0.33  0.012\n",
       "3        19630705    0.40  0.08 -0.27  0.08 -0.33  0.012\n",
       "4        19630708   -0.63  0.04 -0.19 -0.29  0.13  0.012\n",
       "...           ...     ...   ...   ...   ...   ...    ...\n",
       "14509    20210222   -1.12  0.68  3.14  1.66  0.90  0.000\n",
       "14510    20210223   -0.15 -1.05  0.90  1.08 -0.19  0.000\n",
       "14511    20210224    1.15  1.48  1.34 -0.29  0.32  0.000\n",
       "14512    20210225   -2.73 -0.90  0.87  1.00  0.47  0.000\n",
       "14513    20210226   -0.28  0.38 -1.56 -0.06 -0.38  0.000\n",
       "\n",
       "[14514 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "nonprofit-award",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors.rename({\"Unnamed: 0\" : \"Date\"}, inplace=True,axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "threatened-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors.index = factors.Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "duplicate-coral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Mkt-RF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>RMW</th>\n",
       "      <th>CMA</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19630701</th>\n",
       "      <td>19630701</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19630702</th>\n",
       "      <td>19630702</td>\n",
       "      <td>0.79</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19630703</th>\n",
       "      <td>19630703</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19630705</th>\n",
       "      <td>19630705</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19630708</th>\n",
       "      <td>19630708</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20210222</th>\n",
       "      <td>20210222</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>0.68</td>\n",
       "      <td>3.14</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20210223</th>\n",
       "      <td>20210223</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.08</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20210224</th>\n",
       "      <td>20210224</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.34</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20210225</th>\n",
       "      <td>20210225</td>\n",
       "      <td>-2.73</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20210226</th>\n",
       "      <td>20210226</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14514 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date  Mkt-RF   SMB   HML   RMW   CMA     RF\n",
       "Date                                                     \n",
       "19630701  19630701   -0.67  0.00 -0.34 -0.01  0.15  0.012\n",
       "19630702  19630702    0.79 -0.27  0.27 -0.07 -0.19  0.012\n",
       "19630703  19630703    0.63 -0.17 -0.10  0.17 -0.33  0.012\n",
       "19630705  19630705    0.40  0.08 -0.27  0.08 -0.33  0.012\n",
       "19630708  19630708   -0.63  0.04 -0.19 -0.29  0.13  0.012\n",
       "...            ...     ...   ...   ...   ...   ...    ...\n",
       "20210222  20210222   -1.12  0.68  3.14  1.66  0.90  0.000\n",
       "20210223  20210223   -0.15 -1.05  0.90  1.08 -0.19  0.000\n",
       "20210224  20210224    1.15  1.48  1.34 -0.29  0.32  0.000\n",
       "20210225  20210225   -2.73 -0.90  0.87  1.00  0.47  0.000\n",
       "20210226  20210226   -0.28  0.38 -1.56 -0.06 -0.38  0.000\n",
       "\n",
       "[14514 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "inappropriate-there",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date        int64\n",
       "Mkt-RF    float64\n",
       "SMB       float64\n",
       "HML       float64\n",
       "RMW       float64\n",
       "CMA       float64\n",
       "RF        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "minor-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors['Date'] = pd.to_datetime(factors['Date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "according-hindu",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Mkt-RF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>RMW</th>\n",
       "      <th>CMA</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19630701</th>\n",
       "      <td>1963-07-01</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19630702</th>\n",
       "      <td>1963-07-02</td>\n",
       "      <td>0.79</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19630703</th>\n",
       "      <td>1963-07-03</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19630705</th>\n",
       "      <td>1963-07-05</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19630708</th>\n",
       "      <td>1963-07-08</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20210222</th>\n",
       "      <td>2021-02-22</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>0.68</td>\n",
       "      <td>3.14</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20210223</th>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.08</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20210224</th>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.34</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20210225</th>\n",
       "      <td>2021-02-25</td>\n",
       "      <td>-2.73</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20210226</th>\n",
       "      <td>2021-02-26</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14514 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date  Mkt-RF   SMB   HML   RMW   CMA     RF\n",
       "Date                                                      \n",
       "19630701 1963-07-01   -0.67  0.00 -0.34 -0.01  0.15  0.012\n",
       "19630702 1963-07-02    0.79 -0.27  0.27 -0.07 -0.19  0.012\n",
       "19630703 1963-07-03    0.63 -0.17 -0.10  0.17 -0.33  0.012\n",
       "19630705 1963-07-05    0.40  0.08 -0.27  0.08 -0.33  0.012\n",
       "19630708 1963-07-08   -0.63  0.04 -0.19 -0.29  0.13  0.012\n",
       "...             ...     ...   ...   ...   ...   ...    ...\n",
       "20210222 2021-02-22   -1.12  0.68  3.14  1.66  0.90  0.000\n",
       "20210223 2021-02-23   -0.15 -1.05  0.90  1.08 -0.19  0.000\n",
       "20210224 2021-02-24    1.15  1.48  1.34 -0.29  0.32  0.000\n",
       "20210225 2021-02-25   -2.73 -0.90  0.87  1.00  0.47  0.000\n",
       "20210226 2021-02-26   -0.28  0.38 -1.56 -0.06 -0.38  0.000\n",
       "\n",
       "[14514 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adequate-defeat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 1, 1, 0, 0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "hydraulic-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "fama = factors[(factors[\"Date\"] > start) & (factors[\"Date\"] <= '2020-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "weekly-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "fama = fama.iloc[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "durable-savings",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Mkt-RF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>RMW</th>\n",
       "      <th>CMA</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20180103</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20180104</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20180105</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>0.66</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20180108</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20180109</th>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20191224</th>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20191226</th>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20191227</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20191230</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20191231</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>502 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date  Mkt-RF   SMB   HML   RMW   CMA     RF\n",
       "Date                                                      \n",
       "20180103 2018-01-03    0.59 -0.48 -0.20 -0.74 -0.07  0.005\n",
       "20180104 2018-01-04    0.42 -0.23  0.25 -0.02  0.30  0.005\n",
       "20180105 2018-01-05    0.66 -0.36 -0.26  0.39 -0.37  0.005\n",
       "20180108 2018-01-08    0.19 -0.21  0.05 -0.09  0.03  0.005\n",
       "20180109 2018-01-09    0.15 -0.36 -0.05 -0.11 -0.06  0.005\n",
       "...             ...     ...   ...   ...   ...   ...    ...\n",
       "20191224 2019-12-24    0.01  0.36 -0.02 -0.28  0.03  0.007\n",
       "20191226 2019-12-26    0.48 -0.56 -0.02  0.22 -0.20  0.007\n",
       "20191227 2019-12-27   -0.10 -0.54 -0.07  0.25  0.15  0.007\n",
       "20191230 2019-12-30   -0.57  0.27  0.59  0.13  0.45  0.007\n",
       "20191231 2019-12-31    0.28  0.02  0.11 -0.11  0.20  0.007\n",
       "\n",
       "[502 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sustainable-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "fama.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "divided-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "adbe = fama.join(df, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "outdoor-custom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Mkt-RF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>RMW</th>\n",
       "      <th>CMA</th>\n",
       "      <th>RF</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.018621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.011970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>0.66</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.011504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.001620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.008931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.002095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.004721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.001239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.007434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.004467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>502 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Mkt-RF   SMB   HML   RMW   CMA     RF  Adj Close\n",
       "0   2018-01-03    0.59 -0.48 -0.20 -0.74 -0.07  0.005   0.018621\n",
       "1   2018-01-04    0.42 -0.23  0.25 -0.02  0.30  0.005   0.011970\n",
       "2   2018-01-05    0.66 -0.36 -0.26  0.39 -0.37  0.005   0.011504\n",
       "3   2018-01-08    0.19 -0.21  0.05 -0.09  0.03  0.005  -0.001620\n",
       "4   2018-01-09    0.15 -0.36 -0.05 -0.11 -0.06  0.005   0.008931\n",
       "..         ...     ...   ...   ...   ...   ...    ...        ...\n",
       "497 2019-12-24    0.01  0.36 -0.02 -0.28  0.03  0.007   0.002095\n",
       "498 2019-12-26    0.48 -0.56 -0.02  0.22 -0.20  0.007   0.004721\n",
       "499 2019-12-27   -0.10 -0.54 -0.07  0.25  0.15  0.007  -0.001239\n",
       "500 2019-12-30   -0.57  0.27  0.59  0.13  0.45  0.007  -0.007434\n",
       "501 2019-12-31    0.28  0.02  0.11 -0.11  0.20  0.007   0.004467\n",
       "\n",
       "[502 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "oriented-stopping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_07591b30_97c5_11eb_9120_a8a15938f64frow0_col0,#T_07591b30_97c5_11eb_9120_a8a15938f64frow1_col1,#T_07591b30_97c5_11eb_9120_a8a15938f64frow2_col2,#T_07591b30_97c5_11eb_9120_a8a15938f64frow3_col3,#T_07591b30_97c5_11eb_9120_a8a15938f64frow4_col4,#T_07591b30_97c5_11eb_9120_a8a15938f64frow5_col5,#T_07591b30_97c5_11eb_9120_a8a15938f64frow6_col6{\n",
       "            background-color:  #003c30;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow0_col1{\n",
       "            background-color:  #9f6317;\n",
       "            color:  #000000;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow0_col2{\n",
       "            background-color:  #b57826;\n",
       "            color:  #000000;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow0_col3{\n",
       "            background-color:  #714108;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow0_col4{\n",
       "            background-color:  #8d520b;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow0_col5,#T_07591b30_97c5_11eb_9120_a8a15938f64frow4_col1{\n",
       "            background-color:  #6a3d07;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow0_col6{\n",
       "            background-color:  #1d8078;\n",
       "            color:  #000000;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow1_col0,#T_07591b30_97c5_11eb_9120_a8a15938f64frow1_col4,#T_07591b30_97c5_11eb_9120_a8a15938f64frow5_col6{\n",
       "            background-color:  #ebd6a2;\n",
       "            color:  #000000;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow1_col2{\n",
       "            background-color:  #f1e1b5;\n",
       "            color:  #000000;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow1_col3{\n",
       "            background-color:  #894f0a;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow1_col5,#T_07591b30_97c5_11eb_9120_a8a15938f64frow3_col1,#T_07591b30_97c5_11eb_9120_a8a15938f64frow4_col0,#T_07591b30_97c5_11eb_9120_a8a15938f64frow4_col6,#T_07591b30_97c5_11eb_9120_a8a15938f64frow6_col2,#T_07591b30_97c5_11eb_9120_a8a15938f64frow6_col3,#T_07591b30_97c5_11eb_9120_a8a15938f64frow6_col4,#T_07591b30_97c5_11eb_9120_a8a15938f64frow6_col5{\n",
       "            background-color:  #543005;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow1_col6{\n",
       "            background-color:  #f1dfb3;\n",
       "            color:  #000000;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow2_col0{\n",
       "            background-color:  #a16518;\n",
       "            color:  #000000;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow2_col1{\n",
       "            background-color:  #9d6116;\n",
       "            color:  #000000;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow2_col3{\n",
       "            background-color:  #d7b169;\n",
       "            color:  #000000;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow2_col4{\n",
       "            background-color:  #58b0a7;\n",
       "            color:  #000000;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow2_col5{\n",
       "            background-color:  #824b09;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow2_col6{\n",
       "            background-color:  #774508;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow3_col0{\n",
       "            background-color:  #c38936;\n",
       "            color:  #000000;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow3_col2{\n",
       "            background-color:  #f6ecd1;\n",
       "            color:  #000000;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow3_col4{\n",
       "            background-color:  #f5f2e8;\n",
       "            color:  #000000;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow3_col5{\n",
       "            background-color:  #874e0a;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow3_col6{\n",
       "            background-color:  #d2a75c;\n",
       "            color:  #000000;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow4_col2{\n",
       "            background-color:  #64b9ae;\n",
       "            color:  #000000;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow4_col3{\n",
       "            background-color:  #dcbc75;\n",
       "            color:  #000000;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow4_col5,#T_07591b30_97c5_11eb_9120_a8a15938f64frow6_col1{\n",
       "            background-color:  #7c4709;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow5_col0{\n",
       "            background-color:  #dfc37e;\n",
       "            color:  #000000;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow5_col1{\n",
       "            background-color:  #663a07;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow5_col2{\n",
       "            background-color:  #eedbaa;\n",
       "            color:  #000000;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow5_col3{\n",
       "            background-color:  #c08430;\n",
       "            color:  #000000;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow5_col4{\n",
       "            background-color:  #f6e8c3;\n",
       "            color:  #000000;\n",
       "        }#T_07591b30_97c5_11eb_9120_a8a15938f64frow6_col0{\n",
       "            background-color:  #258880;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_07591b30_97c5_11eb_9120_a8a15938f64f\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Mkt-RF</th>        <th class=\"col_heading level0 col1\" >SMB</th>        <th class=\"col_heading level0 col2\" >HML</th>        <th class=\"col_heading level0 col3\" >RMW</th>        <th class=\"col_heading level0 col4\" >CMA</th>        <th class=\"col_heading level0 col5\" >RF</th>        <th class=\"col_heading level0 col6\" >Adj Close</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_07591b30_97c5_11eb_9120_a8a15938f64flevel0_row0\" class=\"row_heading level0 row0\" >Mkt-RF</th>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow0_col0\" class=\"data row0 col0\" >1.00</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow0_col1\" class=\"data row0 col1\" >0.07</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow0_col2\" class=\"data row0 col2\" >-0.24</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow0_col3\" class=\"data row0 col3\" >-0.13</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow0_col4\" class=\"data row0 col4\" >-0.44</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow0_col5\" class=\"data row0 col5\" >-0.00</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow0_col6\" class=\"data row0 col6\" >0.75</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_07591b30_97c5_11eb_9120_a8a15938f64flevel0_row1\" class=\"row_heading level0 row1\" >SMB</th>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow1_col0\" class=\"data row1 col0\" >0.07</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow1_col1\" class=\"data row1 col1\" >1.00</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow1_col2\" class=\"data row1 col2\" >0.06</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow1_col3\" class=\"data row1 col3\" >-0.08</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow1_col4\" class=\"data row1 col4\" >-0.04</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow1_col5\" class=\"data row1 col5\" >-0.05</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow1_col6\" class=\"data row1 col6\" >-0.01</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_07591b30_97c5_11eb_9120_a8a15938f64flevel0_row2\" class=\"row_heading level0 row2\" >HML</th>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow2_col0\" class=\"data row2 col0\" >-0.24</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow2_col1\" class=\"data row2 col1\" >0.06</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow2_col2\" class=\"data row2 col2\" >1.00</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow2_col3\" class=\"data row2 col3\" >0.13</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow2_col4\" class=\"data row2 col4\" >0.60</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow2_col5\" class=\"data row2 col5\" >0.04</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow2_col6\" class=\"data row2 col6\" >-0.51</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_07591b30_97c5_11eb_9120_a8a15938f64flevel0_row3\" class=\"row_heading level0 row3\" >RMW</th>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow3_col0\" class=\"data row3 col0\" >-0.13</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow3_col1\" class=\"data row3 col1\" >-0.08</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow3_col2\" class=\"data row3 col2\" >0.13</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow3_col3\" class=\"data row3 col3\" >1.00</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow3_col4\" class=\"data row3 col4\" >0.15</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow3_col5\" class=\"data row3 col5\" >0.05</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow3_col6\" class=\"data row3 col6\" >-0.20</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_07591b30_97c5_11eb_9120_a8a15938f64flevel0_row4\" class=\"row_heading level0 row4\" >CMA</th>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow4_col0\" class=\"data row4 col0\" >-0.44</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow4_col1\" class=\"data row4 col1\" >-0.04</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow4_col2\" class=\"data row4 col2\" >0.60</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow4_col3\" class=\"data row4 col3\" >0.15</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow4_col4\" class=\"data row4 col4\" >1.00</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow4_col5\" class=\"data row4 col5\" >0.03</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow4_col6\" class=\"data row4 col6\" >-0.61</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_07591b30_97c5_11eb_9120_a8a15938f64flevel0_row5\" class=\"row_heading level0 row5\" >RF</th>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow5_col0\" class=\"data row5 col0\" >-0.00</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow5_col1\" class=\"data row5 col1\" >-0.05</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow5_col2\" class=\"data row5 col2\" >0.04</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow5_col3\" class=\"data row5 col3\" >0.05</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow5_col4\" class=\"data row5 col4\" >0.03</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow5_col5\" class=\"data row5 col5\" >1.00</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow5_col6\" class=\"data row5 col6\" >-0.04</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_07591b30_97c5_11eb_9120_a8a15938f64flevel0_row6\" class=\"row_heading level0 row6\" >Adj Close</th>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow6_col0\" class=\"data row6 col0\" >0.75</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow6_col1\" class=\"data row6 col1\" >-0.01</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow6_col2\" class=\"data row6 col2\" >-0.51</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow6_col3\" class=\"data row6 col3\" >-0.20</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow6_col4\" class=\"data row6 col4\" >-0.61</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow6_col5\" class=\"data row6 col5\" >-0.04</td>\n",
       "                        <td id=\"T_07591b30_97c5_11eb_9120_a8a15938f64frow6_col6\" class=\"data row6 col6\" >1.00</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2462976eef0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = adbe.corr()\n",
    "corr.style.background_gradient(cmap='BrBG').set_precision(2)\n",
    "# 'RdBu_r' & 'BrBG' are other good diverging colormaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-currency",
   "metadata": {},
   "source": [
    "## OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "later-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "embedded-gnome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Mkt-RF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>RMW</th>\n",
       "      <th>CMA</th>\n",
       "      <th>RF</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.018621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.011970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>0.66</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.011504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.001620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.008931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.002095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.004721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.001239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.007434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.004467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>502 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Mkt-RF   SMB   HML   RMW   CMA     RF  Adj Close\n",
       "0   2018-01-03    0.59 -0.48 -0.20 -0.74 -0.07  0.005   0.018621\n",
       "1   2018-01-04    0.42 -0.23  0.25 -0.02  0.30  0.005   0.011970\n",
       "2   2018-01-05    0.66 -0.36 -0.26  0.39 -0.37  0.005   0.011504\n",
       "3   2018-01-08    0.19 -0.21  0.05 -0.09  0.03  0.005  -0.001620\n",
       "4   2018-01-09    0.15 -0.36 -0.05 -0.11 -0.06  0.005   0.008931\n",
       "..         ...     ...   ...   ...   ...   ...    ...        ...\n",
       "497 2019-12-24    0.01  0.36 -0.02 -0.28  0.03  0.007   0.002095\n",
       "498 2019-12-26    0.48 -0.56 -0.02  0.22 -0.20  0.007   0.004721\n",
       "499 2019-12-27   -0.10 -0.54 -0.07  0.25  0.15  0.007  -0.001239\n",
       "500 2019-12-30   -0.57  0.27  0.59  0.13  0.45  0.007  -0.007434\n",
       "501 2019-12-31    0.28  0.02  0.11 -0.11  0.20  0.007   0.004467\n",
       "\n",
       "[502 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "warming-farmer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA', 'RF', 'Adj Close'], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adbe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "supposed-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_imp_features = adbe[['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "excessive-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = adbe[\"Adj Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dimensional-montgomery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Statistics\n",
      "------------------------\n",
      "\n",
      " REGRESSION STATISTICS  \n",
      "\n",
      "------------------------\n",
      "\n",
      "beta             t_stat            p_val\n",
      "\n",
      "[[ 4.07455309e-04  3.95752888e-02  4.84215864e-01]\n",
      " [ 1.18967184e-02  9.98278592e-01  1.59072143e-01]\n",
      " [-1.69860061e-03 -8.28684610e-02  5.33021934e-01]\n",
      " [-7.82942693e-03 -3.53257754e-01  6.38052393e-01]\n",
      " [-3.15059772e-03 -1.04012119e-01  5.41420134e-01]\n",
      " [-1.06938817e-02 -2.63096933e-01  6.03762066e-01]]\n",
      "\n",
      " Joint significance of all coefficients\n",
      " [4.258963865272715e-09, 1.0]\n",
      "R-Square is       \n",
      " 0.7084191013877439\n",
      "Adjusted R Square \n",
      " 0.7054797778130235\n",
      "Standard Error    \n",
      " 0.010254720039623981\n",
      "Observations      \n",
      " 502\n",
      "-------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y = Y\n",
    "T = Y.shape[0];\n",
    "# SPY = DataReader('SPY',  'yahoo', datetime(2020,1,1), datetime(2020,8,31))\n",
    "# F = np.diff(np.log(SPY['Adj Close'].values))\n",
    "F = a_imp_features.values\n",
    "'Add Constant to X'\n",
    "X = np.column_stack([np.ones((T,1)), F])\n",
    "N = X.shape[1]\n",
    "\n",
    "'REGRESSION STARTS:'       \n",
    "'Linear Regression of Y: T x 1 on' \n",
    "'Regressors X: T x N'\n",
    "\n",
    "invXX = np.linalg.inv(X.transpose()@X)\n",
    "'OLS estimator beta: N x 1'\n",
    "beta_hat = invXX@X.transpose()@Y\n",
    "'Predictive value of Y_t using OLS'  \n",
    "y_hat = X@beta_hat;       \n",
    "'Residuals from OLS: Y - X*beta'        \n",
    "residuals = Y - y_hat;            \n",
    "'variance of Y_t or residuals'\n",
    "sigma2 = (1/T)*(residuals.transpose()@residuals)\n",
    "'standard deviation of Y_t or residuals'\n",
    "sig = np.sqrt(sigma2) \n",
    "'variance-covariance matrix of beta_hat'\n",
    "'N x N: on-diagnal variance(beta_j)'\n",
    "'N x N: off-diagnal cov(beta_i, beta_j)'\n",
    "varcov_beta_hat = (sigma2)*invXX\n",
    "var_beta_hat = np.sqrt(T*np.diag(varcov_beta_hat))\n",
    "\n",
    "'Calculate R-square'\n",
    "R_square = 1 - residuals.transpose()@residuals/(T*np.var(Y))\n",
    "adj_R_square = 1-(1-R_square)*(T-1)/(T-N)\n",
    "\n",
    "'Test Each Coefficient: beta_i'\n",
    "'t-test stat: N x 1'\n",
    "t_stat = beta_hat.transpose()/var_beta_hat\n",
    "' t-test significance level: N x 1'\n",
    "p_val_t = 1-ss.norm.cdf(t_stat)\n",
    "\n",
    "'Test of Joint Significance of Model'\n",
    "F_stat = beta_hat.transpose()@varcov_beta_hat@beta_hat/\\\n",
    "         (residuals.transpose()@residuals)\n",
    "'size: (1 x N)*(N x N)*(N x 1)/((1 x T) * (T x 1)) = 1 x 1'\n",
    "\n",
    "p_val_F = 1-ss.chi2.cdf(F_stat,T-N)\n",
    "\n",
    "REPORT = np.column_stack([beta_hat, t_stat,p_val_t])\n",
    "print('Regression Statistics')\n",
    "print('------------------------\\n')\n",
    "print(' REGRESSION STATISTICS  \\n') \n",
    "print('------------------------\\n')\n",
    "print('beta             t_stat            p_val\\n')\n",
    "print(REPORT)\n",
    "print('\\n Joint significance of all coefficients\\n',[F_stat,p_val_F])\n",
    "print('R-Square is       \\n',R_square)\n",
    "print('Adjusted R Square \\n',adj_R_square)\n",
    "print('Standard Error    \\n',sig)\n",
    "print('Observations      \\n',T) \n",
    "print('-------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-plant",
   "metadata": {},
   "source": [
    "### Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "located-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(data, target, significance_level=0.05):\n",
    "    initial_features = data.columns.tolist()\n",
    "    best_features = []\n",
    "    while (len(initial_features)>0):\n",
    "        remaining_features = list(set(initial_features)-set(best_features))\n",
    "        new_pval = pd.Series(index=remaining_features)\n",
    "        for new_column in remaining_features:\n",
    "            model = sm.OLS(target, sm.add_constant(data[best_features+[new_column]])).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        min_p_value = new_pval.min()\n",
    "        if(min_p_value<significance_level):\n",
    "            best_features.append(new_pval.idxmin())\n",
    "        else:\n",
    "            break\n",
    "    return best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ahead-shadow",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = a_imp_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "medium-transformation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adhar\\anaconda3\\envs\\fintech\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \n",
      "C:\\Users\\adhar\\anaconda3\\envs\\fintech\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \n",
      "C:\\Users\\adhar\\anaconda3\\envs\\fintech\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \n",
      "C:\\Users\\adhar\\anaconda3\\envs\\fintech\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \n",
      "C:\\Users\\adhar\\anaconda3\\envs\\fintech\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Mkt-RF', 'HML', 'CMA', 'RMW']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_selection(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-shareware",
   "metadata": {},
   "source": [
    "### Backward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "touched-blackjack",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_elimination(data, target,significance_level = 0.05):\n",
    "    features = data.columns.tolist()\n",
    "    while(len(features)>0):\n",
    "        features_with_constant = sm.add_constant(data[features])\n",
    "        p_values = sm.OLS(target, features_with_constant).fit().pvalues[1:]\n",
    "        max_p_value = p_values.max()\n",
    "        if(max_p_value >= significance_level):\n",
    "            excluded_feature = p_values.idxmax()\n",
    "            features.remove(excluded_feature)\n",
    "        else:\n",
    "            break \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "stupid-simple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mkt-RF', 'HML', 'RMW', 'CMA']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backward_elimination(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-darwin",
   "metadata": {},
   "source": [
    "### Mixed Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "adaptive-triangle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "banned-removal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Mkt-RF', 'HML', 'RMW', 'CMA')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sffs = SFS(LinearRegression(),\n",
    "         k_features=(2,4),\n",
    "         forward=True,\n",
    "         floating=True,\n",
    "         cv=5)\n",
    "sffs.fit(X, Y)\n",
    "sffs.k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "vital-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_imp_features = adbe[['Mkt-RF', 'HML', 'RMW', 'CMA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "voluntary-savings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Statistics\n",
      "------------------------\n",
      "\n",
      " REGRESSION STATISTICS  \n",
      "\n",
      "------------------------\n",
      "\n",
      "beta             t_stat            p_val\n",
      "\n",
      "[[ 4.36852894e-04  4.23107957e-02  4.83125470e-01]\n",
      " [ 1.18510328e-02  9.92110150e-01  1.60571898e-01]\n",
      " [-8.03765435e-03 -3.63759339e-01  6.41981136e-01]\n",
      " [-2.94750783e-03 -9.72939856e-02  5.38753534e-01]\n",
      " [-1.04684586e-02 -2.57247902e-01  6.01506296e-01]]\n",
      "\n",
      " Joint significance of all coefficients\n",
      " [3.8987340730498786e-09, 1.0]\n",
      "R-Square is       \n",
      " 0.7064167623372359\n",
      "Adjusted R Square \n",
      " 0.7040539193781795\n",
      "Standard Error    \n",
      " 0.010289870310637314\n",
      "Observations      \n",
      " 502\n",
      "-------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y = Y\n",
    "T = Y.shape[0];\n",
    "# SPY = DataReader('SPY',  'yahoo', datetime(2020,1,1), datetime(2020,8,31))\n",
    "# F = np.diff(np.log(SPY['Adj Close'].values))\n",
    "F = a_imp_features.values\n",
    "'Add Constant to X'\n",
    "X = np.column_stack([np.ones((T,1)), F])\n",
    "N = X.shape[1]\n",
    "\n",
    "'REGRESSION STARTS:'       \n",
    "'Linear Regression of Y: T x 1 on' \n",
    "'Regressors X: T x N'\n",
    "\n",
    "invXX = np.linalg.inv(X.transpose()@X)\n",
    "'OLS estimator beta: N x 1'\n",
    "beta_hat = invXX@X.transpose()@Y\n",
    "'Predictive value of Y_t using OLS'  \n",
    "y_hat = X@beta_hat;       \n",
    "'Residuals from OLS: Y - X*beta'        \n",
    "residuals = Y - y_hat;            \n",
    "'variance of Y_t or residuals'\n",
    "sigma2 = (1/T)*(residuals.transpose()@residuals)\n",
    "'standard deviation of Y_t or residuals'\n",
    "sig = np.sqrt(sigma2) \n",
    "'variance-covariance matrix of beta_hat'\n",
    "'N x N: on-diagnal variance(beta_j)'\n",
    "'N x N: off-diagnal cov(beta_i, beta_j)'\n",
    "varcov_beta_hat = (sigma2)*invXX\n",
    "var_beta_hat = np.sqrt(T*np.diag(varcov_beta_hat))\n",
    "\n",
    "'Calculate R-square'\n",
    "R_square = 1 - residuals.transpose()@residuals/(T*np.var(Y))\n",
    "adj_R_square = 1-(1-R_square)*(T-1)/(T-N)\n",
    "\n",
    "'Test Each Coefficient: beta_i'\n",
    "'t-test stat: N x 1'\n",
    "t_stat = beta_hat.transpose()/var_beta_hat\n",
    "' t-test significance level: N x 1'\n",
    "p_val_t = 1-ss.norm.cdf(t_stat)\n",
    "\n",
    "'Test of Joint Significance of Model'\n",
    "F_stat = beta_hat.transpose()@varcov_beta_hat@beta_hat/\\\n",
    "         (residuals.transpose()@residuals)\n",
    "'size: (1 x N)*(N x N)*(N x 1)/((1 x T) * (T x 1)) = 1 x 1'\n",
    "\n",
    "p_val_F = 1-ss.chi2.cdf(F_stat,T-N)\n",
    "\n",
    "REPORT = np.column_stack([beta_hat, t_stat,p_val_t])\n",
    "print('Regression Statistics')\n",
    "print('------------------------\\n')\n",
    "print(' REGRESSION STATISTICS  \\n') \n",
    "print('------------------------\\n')\n",
    "print('beta             t_stat            p_val\\n')\n",
    "print(REPORT)\n",
    "print('\\n Joint significance of all coefficients\\n',[F_stat,p_val_F])\n",
    "print('R-Square is       \\n',R_square)\n",
    "print('Adjusted R Square \\n',adj_R_square)\n",
    "print('Standard Error    \\n',sig)\n",
    "print('Observations      \\n',T) \n",
    "print('-------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-grill",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "illegal-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "physical-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = a_imp_features, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "social-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dmatrix = xgb.DMatrix(data=X,label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "elder-direction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "senior-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.001,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "nuclear-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg.fit(X_train,y_train)\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "tight-wales",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.494185\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-increase",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "coastal-boston",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "gothic-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "severe-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size= 7 * len(X) // 10,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "mineral-warehouse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV 1/3] END ............................learning_rate=0.001; total time=   0.0s\n",
      "[CV 2/3] END ............................learning_rate=0.001; total time=   0.0s\n",
      "[CV 3/3] END ............................learning_rate=0.001; total time=   0.0s\n",
      "[CV 1/3] END .............................learning_rate=0.01; total time=   0.0s\n",
      "[CV 2/3] END .............................learning_rate=0.01; total time=   0.0s\n",
      "[CV 3/3] END .............................learning_rate=0.01; total time=   0.0s\n",
      "[CV 1/3] END ..............................learning_rate=0.1; total time=   0.0s\n",
      "[CV 2/3] END ..............................learning_rate=0.1; total time=   0.0s\n",
      "[CV 3/3] END ..............................learning_rate=0.1; total time=   0.0s\n",
      "[CV 1/3] END ..............................learning_rate=1.0; total time=   0.0s\n",
      "[CV 2/3] END ..............................learning_rate=1.0; total time=   0.0s\n",
      "[CV 3/3] END ..............................learning_rate=1.0; total time=   0.0s\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=100, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "def _train_xgb(X_train, y_train, X_test, y_test):\n",
    "    xg_reg = xgb.XGBRegressor()\n",
    "    \n",
    "    # Dictionary of all values we want to test for n_estimators\n",
    "    params_xgb = {'learning_rate': [0.001, 0.01, 0.1, 1.0]}\n",
    "    # Use gridsearch to test all values for all n estimators\n",
    "    xgb_gs = GridSearchCV(xg_reg, params_xgb , cv=tscv, verbose=5)\n",
    "    # Fit model to training data\n",
    "    xgb_gs.fit(X_train, y_train)\n",
    "    \n",
    "    # Save best model\n",
    "    xgb_best = xgb_gs.best_estimator_\n",
    "    print(xgb_best) \n",
    "    # Check best n_neigbors value\n",
    "#     print(xgb_best.best_params_)\n",
    "    \n",
    "    prediction = xgb_best.predict(X_test)\n",
    "\n",
    "#     print(classification_report(y_test, prediction))\n",
    "#     print(confusion_matrix(y_test, prediction))\n",
    "    \n",
    "    return xgb_best\n",
    "xgb_model = _train_xgb(X_train, y_train, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "retained-geography",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_best' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-760c1c9489fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxgb_best\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb_best' is not defined"
     ]
    }
   ],
   "source": [
    "xgb_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "accepting-sussex",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "third-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = make_pipeline(StandardScaler(),SGDRegressor(max_iter=1000, tol=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fabulous-contemporary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('sgdregressor', SGDRegressor())])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "physical-junior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('standardscaler', StandardScaler()),\n",
       "  ('sgdregressor', SGDRegressor())],\n",
       " 'verbose': False,\n",
       " 'standardscaler': StandardScaler(),\n",
       " 'sgdregressor': SGDRegressor(),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'sgdregressor__alpha': 0.0001,\n",
       " 'sgdregressor__average': False,\n",
       " 'sgdregressor__early_stopping': False,\n",
       " 'sgdregressor__epsilon': 0.1,\n",
       " 'sgdregressor__eta0': 0.01,\n",
       " 'sgdregressor__fit_intercept': True,\n",
       " 'sgdregressor__l1_ratio': 0.15,\n",
       " 'sgdregressor__learning_rate': 'invscaling',\n",
       " 'sgdregressor__loss': 'squared_loss',\n",
       " 'sgdregressor__max_iter': 1000,\n",
       " 'sgdregressor__n_iter_no_change': 5,\n",
       " 'sgdregressor__penalty': 'l2',\n",
       " 'sgdregressor__power_t': 0.25,\n",
       " 'sgdregressor__random_state': None,\n",
       " 'sgdregressor__shuffle': True,\n",
       " 'sgdregressor__tol': 0.001,\n",
       " 'sgdregressor__validation_fraction': 0.1,\n",
       " 'sgdregressor__verbose': 0,\n",
       " 'sgdregressor__warm_start': False}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "olympic-dimension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV 1/3] END learning_rate=optimal, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END learning_rate=optimal, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END learning_rate=optimal, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END learning_rate=optimal, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END learning_rate=optimal, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END learning_rate=optimal, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END learning_rate=optimal, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END learning_rate=optimal, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END learning_rate=optimal, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END ..learning_rate=optimal, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END ..learning_rate=optimal, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END ..learning_rate=optimal, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END ..learning_rate=optimal, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END ..learning_rate=optimal, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END ..learning_rate=optimal, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "SGDRegressor(learning_rate='optimal', loss='squared_epsilon_insensitive')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "score() missing 2 required positional arguments: 'X' and 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-0bd335022cbd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msgd_best\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0msgd_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_train_sgd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-79-0bd335022cbd>\u001b[0m in \u001b[0;36m_train_sgd\u001b[1;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mmape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m#     r2 = sgd_bestscore(X, y, sample_weight=None)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msgd_best\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: score() missing 2 required positional arguments: 'X' and 'y'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def _train_sgd(X_train, y_train, X_test, y_test):\n",
    "    sgd_reg = SGDRegressor()\n",
    "    \n",
    "    # Dictionary of all values we want to test for n_estimators\n",
    "    params_sgd = {'learning_rate': ['optimal'],\n",
    "                 'loss': ['squared_loss', 'huber', 'squared_epsilon_insensitive'],\n",
    "                  'penalty': ['l2', 'l1', 'elasticnet']}\n",
    "    # Use gridsearch to test all values for all n estimators\n",
    "    sgd_gs = GridSearchCV(sgd_reg, params_sgd , cv=tscv, verbose=5)\n",
    "    # Fit model to training data\n",
    "    sgd_gs.fit(X_train, y_train)\n",
    "    \n",
    "    # Save best model\n",
    "    sgd_best = sgd_gs.best_estimator_\n",
    "    print(sgd_best) \n",
    "    # Check best n_neigbors value\n",
    "#     print(sgd_best.best_params_)\n",
    "    \n",
    "    prediction = sgd_best.predict(X_test)\n",
    "    rms = mean_squared_error(y_test, prediction, squared=False)\n",
    "    mape = np.mean(np.abs((y_test - prediction) / y_test)) * 100\n",
    "#     r2 = sgd_bestscore(X, y, sample_weight=None)\n",
    "    print(sgd_best.score())\n",
    "    print(mape)\n",
    "    print(rms)\n",
    "#     print(classification_report(y_test, prediction))\n",
    "#     print(confusion_matrix(y_test, prediction))\n",
    "    print()\n",
    "    return sgd_best\n",
    "sgd_model = _train_sgd(X_train, y_train, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "other-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score(X, y, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "discrete-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "worldwide-inspiration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "[CV 1/3] END alpha=0.1, learning_rate=constant, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=constant, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=constant, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=constant, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=constant, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=constant, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=constant, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=constant, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=constant, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=constant, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=constant, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=constant, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=constant, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=constant, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=constant, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=constant, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=constant, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=constant, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=constant, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=constant, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=constant, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=constant, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=constant, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=constant, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=constant, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=constant, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=constant, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=optimal, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=optimal, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=optimal, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=optimal, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=optimal, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=optimal, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=optimal, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=optimal, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=optimal, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=invscaling, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=invscaling, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=invscaling, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=invscaling, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=invscaling, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=invscaling, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=invscaling, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=invscaling, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=invscaling, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=invscaling, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=invscaling, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=invscaling, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=invscaling, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=invscaling, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=invscaling, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.1, learning_rate=invscaling, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.1, learning_rate=invscaling, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.1, learning_rate=invscaling, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=constant, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=constant, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=constant, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=constant, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=constant, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=constant, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=constant, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=constant, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=constant, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=constant, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=constant, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=constant, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=constant, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=constant, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=constant, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=constant, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=constant, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=constant, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=constant, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=constant, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=constant, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=constant, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=constant, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=constant, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=constant, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=constant, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=constant, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=optimal, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=optimal, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=optimal, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=optimal, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=optimal, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=optimal, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=optimal, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=optimal, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=optimal, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=invscaling, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=invscaling, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=invscaling, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=invscaling, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=invscaling, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=invscaling, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END alpha=0.01, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=invscaling, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=invscaling, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=invscaling, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=invscaling, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=invscaling, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=invscaling, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=invscaling, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=invscaling, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=invscaling, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.01, learning_rate=invscaling, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.01, learning_rate=invscaling, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.01, learning_rate=invscaling, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=constant, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=constant, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=constant, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=constant, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=constant, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=constant, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=constant, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=constant, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=constant, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=constant, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=constant, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=constant, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=constant, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=constant, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=constant, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=constant, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=constant, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=constant, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=constant, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=constant, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=constant, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=constant, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=constant, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=constant, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=constant, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=constant, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=constant, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=optimal, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=optimal, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=optimal, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=optimal, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=optimal, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=optimal, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=optimal, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=optimal, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=optimal, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=invscaling, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=invscaling, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=invscaling, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=invscaling, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=invscaling, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=invscaling, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=invscaling, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=invscaling, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=invscaling, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=invscaling, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=invscaling, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=invscaling, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=invscaling, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=invscaling, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=invscaling, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.001, learning_rate=invscaling, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.001, learning_rate=invscaling, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.001, learning_rate=invscaling, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=constant, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=constant, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=constant, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=constant, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=constant, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=constant, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=constant, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=constant, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=constant, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=constant, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=constant, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=constant, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=constant, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=constant, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=constant, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=constant, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=constant, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=constant, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=optimal, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=optimal, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=optimal, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=optimal, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=optimal, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=optimal, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=optimal, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=optimal, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=optimal, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=invscaling, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=invscaling, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=invscaling, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=invscaling, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=invscaling, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=invscaling, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=invscaling, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=invscaling, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=invscaling, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=invscaling, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=invscaling, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=invscaling, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=invscaling, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=invscaling, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=invscaling, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=constant, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=constant, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=constant, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-05, learning_rate=invscaling, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-05, learning_rate=invscaling, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-05, learning_rate=invscaling, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=constant, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=constant, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=constant, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=constant, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=constant, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=constant, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=constant, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=constant, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=constant, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=constant, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=constant, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=constant, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=constant, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=constant, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=constant, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=constant, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=constant, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=constant, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=constant, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=constant, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=constant, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=constant, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=constant, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=constant, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=constant, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=constant, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=constant, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END alpha=1e-06, learning_rate=optimal, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=optimal, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=optimal, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=optimal, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=optimal, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=optimal, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=optimal, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=optimal, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=optimal, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=invscaling, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=invscaling, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=invscaling, loss=squared_loss, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=invscaling, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=invscaling, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=invscaling, loss=squared_loss, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=invscaling, loss=squared_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=invscaling, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=invscaling, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=invscaling, loss=huber, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=invscaling, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=invscaling, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=invscaling, loss=huber, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=invscaling, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=invscaling, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=invscaling, loss=huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l2; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=invscaling, loss=epsilon_insensitive, penalty=l1; total time=   0.0s\n",
      "[CV 1/3] END alpha=1e-06, learning_rate=invscaling, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 2/3] END alpha=1e-06, learning_rate=invscaling, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "[CV 3/3] END alpha=1e-06, learning_rate=invscaling, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.0s\n",
      "SGDRegressor(alpha=1e-06, learning_rate='constant', penalty='elasticnet')\n",
      "Best score: 0.6030054108543158\n",
      "292.0030858001363\n",
      "0.010952998398974234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def _train_sgd(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    sgd_reg = SGDRegressor()\n",
    "    \n",
    "    # Dictionary of all values we want to test for n_estimators\n",
    "    params_sgd = {\n",
    "    'alpha': 10.0 ** -np.arange(1, 7),\n",
    "    'loss': ['squared_loss', 'huber', 'epsilon_insensitive'],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling']}\n",
    "    # Use gridsearch to test all values for all n estimators\n",
    "    sgd_gs = GridSearchCV(sgd_reg, params_sgd , cv=tscv, verbose=5)\n",
    "    # Fit model to training data\n",
    "    sgd_gs.fit(X_train, y_train)\n",
    "    \n",
    "    # Save best model\n",
    "    sgd_best = sgd_gs.best_estimator_\n",
    "    print(sgd_best) \n",
    "    print(\"Best score: \" + str(sgd_gs.best_score_))\n",
    "    # Check best n_neigbors value\n",
    "#     print(sgd_best.best_params_)\n",
    "    \n",
    "    prediction = sgd_best.predict(X_test)\n",
    "    rms = mean_squared_error(y_test, prediction, squared=False)\n",
    "    mape = np.mean(np.abs((y_test - prediction) / y_test)) * 100\n",
    "#     r2 = sgd_bestscore(X, y, sample_weight=None)\n",
    "#     print(sgd_best.score())\n",
    "    print(mape)\n",
    "    print(rms)\n",
    "#     print(classification_report(y_test, prediction))\n",
    "#     print(confusion_matrix(y_test, prediction))\n",
    "    print()\n",
    "    return sgd_best\n",
    "sgd_model = _train_sgd(X_train, y_train, X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-heather",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "advisory-power",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1, 'fit_intercept': False, 'solver': 'lsqr'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_reg = Ridge()\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params_Ridge = {'alpha': [1,0.1,0.01,0.001,0.0001,0] , \"fit_intercept\": [True, False], \"solver\": ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']}\n",
    "Ridge_GS = GridSearchCV(ridge_reg, param_grid=params_Ridge, n_jobs=-1)\n",
    "Ridge_GS.fit(X_train, y_train)\n",
    "Ridge_GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "instructional-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "packed-platform",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.594) total time=   0.0s\n",
      "[CV] END ................................ score: (test=0.584) total time=   0.0s\n",
      "[CV] END ................................ score: (test=0.811) total time=   0.0s\n",
      "[CV] END ................................ score: (test=0.781) total time=   0.0s\n",
      "[CV] END ................................ score: (test=0.478) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.59399591, 0.58446439, 0.81076475, 0.78101125, 0.47759903])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridgeregression = Ridge(random_state=3, **Ridge_GS.best_params_)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "all_accuracies = cross_val_score(estimator=Ridgeregression, X=X_train, y=y_train, cv=tscv, verbose = 5)\n",
    "all_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dressed-venture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6495670669845296\n"
     ]
    }
   ],
   "source": [
    "print(all_accuracies.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "logical-preservation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.558397020190914"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridge_GS.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-router",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fintech",
   "language": "python",
   "name": "fintech"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
